{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mindspore.dataset\n",
    "import mindspore.dataset as ds # 数据集载入算子\n",
    "import mindspore.dataset.transforms.c_transforms as C # 常用转化算子\n",
    "import mindspore.dataset.vision.c_transforms as CV # 图像转化算子\n",
    "\n",
    "# mindspore.common\n",
    "from mindspore.common import dtype as mstype # 数据形态转换\n",
    "from mindspore.common.initializer import Normal # 参数初始化\n",
    "\n",
    "# mindspore.nn\n",
    "import mindspore.nn as nn # 各类网络层都在nn里面\n",
    "from mindspore.nn.metrics import Accuracy # 测试模型用\n",
    "\n",
    "\n",
    "from mindspore import Model # 承载网络结构\n",
    "\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\n",
    "\n",
    "# os模块处理数据路径用\n",
    "import os\n",
    "\n",
    "# numpy\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_path, batch_size=32):\n",
    "    \"\"\" \n",
    "    数据预处理与批量输出的函数\n",
    "    \n",
    "    Args:\n",
    "        data_path: 数据路径\n",
    "        batch_size: 批量大小\n",
    "    \"\"\"\n",
    "    \n",
    "    # 定义数据集\n",
    "    data = ds.MnistDataset(data_path)\n",
    "    \n",
    "    # 打乱数据集\n",
    "    data = data.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # 数据标准化参数\n",
    "    # MNIST数据集的 mean = 33.3285，std = 78.5655\n",
    "    mean, std = 33.3285, 78.5655 \n",
    "\n",
    "    # 定义算子\n",
    "    nml_op = lambda x : np.float32((x-mean)/std) # 数据标准化，image = (image-mean)/std\n",
    "    hwc2chw_op = CV.HWC2CHW() # 通道前移（为配适网络，CHW的格式可最佳发挥昇腾芯片算力）\n",
    "    type_cast_op = C.TypeCast(mstype.int32) # 原始数据的标签是unint，计算损失需要int\n",
    "\n",
    "    # 算子运算\n",
    "    data = data.map(operations=type_cast_op, input_columns='label')\n",
    "    data = data.map(operations=nml_op, input_columns='image')\n",
    "    data = data.map(operations=hwc2chw_op, input_columns='image')\n",
    "\n",
    "    # 批处理\n",
    "    data = data.batch(batch_size)\n",
    "    \n",
    "    # 重复\n",
    "    data = data.repeat(1)\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Cell):\n",
    "    \n",
    "    # 定义算子\n",
    "    def __init__(self, num_class=10, num_channel=1):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Dense(4 * 4 * 16, 120, weight_init=Normal(0.02))\n",
    "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "        \n",
    "        # 激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # 最大池化层\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 网络展开\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    # 建构网络\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join('data', 'train')  # 训练集路径\n",
    "train_data = create_dataset(train_path)  # 定义训练数据集\n",
    "\n",
    "val_path = os.path.join('data', 'val')  # 测试集路径\n",
    "val_data = create_dataset(val_path)  # 定义测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mindspore.dataset.engine.datasets.RepeatDataset object at 0x0000025683BB1408>\n",
      "(32, 1, 28, 28)\n",
      "(32, 1, 28, 28)\n",
      "(32, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "for i,dic in enumerate(train_data.create_dict_iterator()):\n",
    "    print(dic['image'].shape)\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络\n",
    "net = LeNet5()\n",
    "\n",
    "# 损失函数\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "\n",
    "# 优化器\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "net_opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "\n",
    "# 模型\n",
    "model = Model(net, net_loss, net_opt, metrics={'accuracy': Accuracy()}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, lr=0.01, momentum=0.9, num_epochs=3):\n",
    "    ds_train = create_dataset(data_dir)\n",
    "    ds_eval = create_dataset(data_dir, training=False)\n",
    "    net = LeNet5()\n",
    "    loss = nn.loss.SoftmaxCrossEntropyWithLogits(is_grad=False, sparse=True, reduction='mean')\n",
    "    opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "    \n",
    "    model = Model(net, loss, opt, metrics={'acc', 'loss'})\n",
    "    # dataset_sink_mode can be True when using Ascend\n",
    "    model.train(num_epochs, ds_train, callbacks=[loss_cb], dataset_sink_mode=False)\n",
    "    metrics = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    print('Metrics:', metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(18732:23472,MainProcess):2022-06-07-14:55:58.584.181 [mindspore\\train\\model.py:500] The CPU cannot support dataset sink mode currently.So the training process will be performed with dataset not sink.\n"
     ]
    }
   ],
   "source": [
    "# 设置模型保存\n",
    "ckpt_cfg = CheckpointConfig(save_checkpoint_steps=1, keep_checkpoint_max=5)\n",
    "ckpt_cb = ModelCheckpoint(prefix=\"my_ckpt\", directory='ckpt', config=ckpt_cfg)\n",
    "# 训练3个epoch \n",
    "model.train(3, train_data, callbacks=[ckpt_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(18732:23472,MainProcess):2022-06-07-14:57:14.740.286 [mindspore\\train\\model.py:893] CPU cannot support dataset sink mode currently.So the evaluating process will be performed with dataset non-sink mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9823}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval(val_data)  # 测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用现成模型进行推理\n",
    "CKPT_2 = 'ckpt/my_ckpt-3_1875.ckpt'\n",
    "def infer(data_dir):\n",
    "#     ds = create_dataset(data_dir, training=False).create_dict_iterator()\n",
    "    ds = create_dataset(data_dir).create_dict_iterator()\n",
    "    data = ds.get_next()\n",
    "    images = data['image']\n",
    "#     labels = data['label']\n",
    "    net = LeNet5()\n",
    "    load_checkpoint(CKPT_2, net=net)\n",
    "    model = Model(net)\n",
    "    output = model.predict(Tensor(data['image']))\n",
    "#     output = model.eval(Tensor(data['image']))\n",
    "    preds = np.argmax(output.asnumpy(), axis=1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore(1.5.0)",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
